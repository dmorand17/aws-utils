#!/usr/bin/env bash

# Put into .ssh/config like this:
# host i-* mi-*
# ProxyCommand sh -c "/path/to/ssm-over-ssm.sh '%r' '%h' '%p'"
#
# Then you can SSH-via-SessionManager using a command like this:
# ssh ec2-user@i-07e9bd6d3497545cd,eu-west-2
# SCP works too:
# scp ec2-user@i-07e9bd6d3497545cd,eu-west-2:.bash_history history
#
# Works on instances that have both amazon-ssm-agent and ec2-instance-connect installed (e.g. any recent Amazon Linux).
# Credentials for AWS supplied in the normal fashion (environment variables, ~/.aws/credentials, etc.)

set -eou pipefail

SSH_HOME=$HOME/.ssh
SSH_TMP_KEY=${SSH_HOME}/ssh-ssm-tmp

target="$1"

exe() { echo "\$ $*" ; "$@" ; }

clean_ssh_keys () { rm -f ${SSH_TMP_KEY}{,.pub}; }

# Create ssh key if it doesn't exist
make_ssh_keys() {
  if [[ -f ${SSH_TMP_KEY} ]]; then
    ssh-keygen -f "${SSH_TMP_KEY}" -N ''
  fi
}

if [[ "${target}" =~ (m?i-[0-9a-f]+)(,([a-z0-9-]+))? ]]; then
  instance_id="${BASH_REMATCH[1]}"
  [[ "${BASH_REMATCH[3]}" != "" ]] && export AWS_DEFAULT_REGION="${BASH_REMATCH[3]}"
else
  echo >&2 "Could not parse: ${target}"
  exit 1
fi

echo >&2 "$(tput setaf 5)get instance details$(tput setaf 7)"
# Look up the AZ of the instance
az="$( aws ec2 describe-instances --instance-id "${instance_id}" | jq -r '.Reservations[0].Instances[0].Placement.AvailabilityZone' )"

echo >&2 "$(tput setaf 5)start session$(tput setaf 7)"

# Add the public key to .ssh/authorized_keys file
command_id=$(aws ssm send-command \
  --instance-ids "$1" \
  --document-name "AWS-RunShellScript" \
  --parameters commands="${ssm_cmd}" \
  --comment "temporary ssm ssh access" \
  --output text \
  --query Command.CommandId)

# wait for successful send-command execution
aws ssm wait command-executed --instance-id "$1" --command-id "${command_id}"

# start ssh session over ssm
exe aws ssm start-session --document-name AWS-StartSSHSession --target "$1"
